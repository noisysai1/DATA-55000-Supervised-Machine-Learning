# -*- coding: utf-8 -*-
"""project 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-73YVIE0FHJsBIOZyoKlNvATZ1umGAez

Supervised Machine Learning

Sai kumar Murarishetti

Week 7 : Final Project Part 2

(https:/https://www.kaggle.com/datasets/asishpandey/crop-production-in-india/data//)
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, mean_squared_error
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical
from google.colab import files

# This is used to upload the dataset
df=files.upload()
data = pd.read_csv('Crop_production.csv')

# This is used to display first 10 lines from the dataset
print(data.head(10))

# This is used to Display a summary of DataFrame 'df' for data inspection and understanding.
print(data.info)

#this is used to display rows and colums
data.shape

#This is Generate descriptive statistics for numeric columns in DataFrame.
data.describe()

#This is a square DataFrame where each cell contains the correlation coefficient between two columns
data.corr()

# This is used to create histograms for all the numeric columns
data.hist()

# Data preprocessing
# This for assuming you a target column classification

X = data.drop(columns=['State_Name', 'Crop_Type', 'Crop'])
y = data['Crop_Type']

#printing of columns
print(data.columns)

# this is to Encode the target variable
le = LabelEncoder()
y = le.fit_transform(y)

#This is for Dropping varaibles columns from the dataset
data = data.drop(columns=['State_Name', 'Crop_Type',  'Crop'])

# this will Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Technique 1: Logistic Regression

logistic_model = LogisticRegression()
logistic_model.fit(X_train, y_train)
logistic_predictions = logistic_model.predict(X_test)

# Evaluate the Logistic Regression model

print("Logistic Regression Model:")
print("Classification Report:\n", classification_report(y_test, logistic_predictions))
print("Accuracy Score:", accuracy_score(y_test, logistic_predictions))

# Technique 2: Decision Tree Classifier Model

from sklearn import tree
model=tree.DecisionTreeClassifier(criterion="entropy")
model.fit(X_train, y_train)
y_pred=model.predict(X_test)

# Evaluate Decision Tree Classifier Model

print(y_pred)
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Accuracy Score:", accuracy_score(y_test, y_pred*100))