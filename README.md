# DATA-55000-Supervised-Machine-Learning
Coursework, assignments and projects for DATA-55000: Supervised Machine Learning 
# üß† DATA-55000 ‚Äî Supervised Machine Learning 
---

## üìò Course Overview
This repository documents my complete 8-week journey through **DATA-55000: Supervised Machine Learning**, covering both theoretical foundations and applied machine learning techniques.  
Each week includes practical assignments, Jupyter notebooks, Python scripts and final project deliverables ‚Äî progressing from basic concepts to a full-scale predictive analytics project on 
**Crop Production Forecasting**.

---

## üóìÔ∏è Weekly Breakdown

### üß© **Week 1 ‚Äî Introduction to Supervised Learning**
**Topics Covered:**
- Concept of Supervised vs Unsupervised Learning  
- Training vs Testing datasets  
- Basic workflow of machine learning (data, model, evaluation)  
- Linear regression fundamentals  
- Model evaluation metrics (MAE, MSE, RMSE, R¬≤)

**Key Learnings:**
- Understood the difference between training and inference phases.  
- Learned how to evaluate regression models using real-world examples.  
- Implemented the first supervised learning workflow using Python and Scikit-learn.  

---

### üìä **Week 2 ‚Äî Linear Regression and Model Evaluation**
**Topics Covered:**
- Simple & Multiple Linear Regression  
- Gradient Descent and Cost Function  
- Model evaluation using R¬≤ and Adjusted R¬≤  
- Residual analysis and error visualization  

**Key Learnings:**
- Built regression models using `sklearn.linear_model.LinearRegression`.  
- Visualized residuals and error distributions.  
- Learned how model complexity affects bias and variance.  

---

### üìà **Week 3 ‚Äî Maximum Likelihood, Naive Bayes, and PCA**
**Topics Covered:**
- Maximum Likelihood Estimation (MLE)  
- Gaussian Naive Bayes classifier  
- Covariance and correlation analysis  
- Dimensionality reduction using Principal Component Analysis (PCA)

**Key Learnings:**
- Estimated mean and variance using MLE.  
- Classified text documents with Naive Bayes.  
- Applied PCA to visualize high-dimensional datasets with Scree plots.  

---

### üî¢ **Week 4 ‚Äî Logistic Regression, Linear Models, and Regularization**
**Topics Covered:**
- Logistic Regression for classification  
- Perceptron and Sigmoid activation  
- Polynomial regression and feature engineering  
- L1/L2 regularization and overfitting control  
- Kernel PCA and manifold learning  

**Key Learnings:**
- Implemented logistic regression to predict categorical outcomes.  
- Visualized decision boundaries and regularization effects.  
- Understood how feature scaling affects model performance.  
- Used Kernel PCA for non-linear feature transformation.  

---

### ü§ñ **Week 5 ‚Äî Neural Networks & Multilayer Perceptrons**
**Topics Covered:**
- Neural network architecture and perceptron learning  
- Activation functions (Sigmoid, Tanh, ReLU, Softplus)  
- Regularization and dropout  
- Building MLPs using Keras and TensorFlow  
- Applications: notMNIST classification, advertising regression, and KDD Cup dataset  

**Key Learnings:**
- Built and trained deep neural networks for classification and regression.  
- Compared model performance using different optimizers and learning rates.  
- Understood overfitting and the importance of regularization in neural networks.  
- Developed intuition for network architecture design.  

---

### üåæ **Week 6 ‚Äî Project Part 1: Crop Production Data Exploration**
**Topics Covered:**
- Exploratory Data Analysis (EDA) on agricultural dataset  
- Correlation between soil nutrients, rainfall, and yield  
- Visualization of histograms and relationships  
- Feature understanding and data preparation  

**Key Learnings:**
- Conducted EDA on the **Crop Production dataset (99,849 rows √ó 13 columns)**.  
- Found correlations between nitrogen (N), phosphorus (P), and potassium (K).  
- Prepared and cleaned data for supervised learning models.  
- Realized the importance of statistical summaries and visual exploration before modeling.  

---

### üå± **Week 7 ‚Äî Project Part 2: Model Building & Evaluation**
**Topics Covered:**
- Supervised ML model implementation for crop type classification  
- Logistic Regression, Decision Tree, and Random Forest models  
- Train-test splitting, feature scaling, and label encoding  
- Model comparison using accuracy, precision, recall, and F1-score  

**Key Learnings:**
- Achieved **87.26% accuracy with Logistic Regression** and **92% with Random Forest**.  
- Understood overfitting in Decision Trees and benefits of ensemble methods.  
- Built an end-to-end ML pipeline from preprocessing to model evaluation.  
- Demonstrated real-world application of ML in agriculture and yield forecasting.  

---

### üìÑ **Week 8 ‚Äî Final IEEE Research Paper**
**Topics Covered:**
- Final integration of the project into an IEEE-format research paper  
- Multi-model comparison: Linear, Logistic, Decision Tree, Random Forest, SVM  
- Analysis of environmental and soil factors affecting crop yield  
- Discussion of sustainability and AI-driven agriculture  

**Key Learnings:**
- Authored an IEEE-style paper consolidating all findings and models.  
- Presented data-driven agricultural insights for predictive policymaking.  
- Evaluated models for accuracy, robustness, and interpretability.  
- Understood the ethical and societal impact of AI in sustainable agriculture.  

---

## üßÆ Tools, Technologies & Libraries Used
| Category | Tools / Libraries |
|-----------|-------------------|
| Programming | Python 3, Google Colab, Jupyter Notebook |
| ML Frameworks | Scikit-learn, TensorFlow, Keras |
| Data Handling | Pandas, NumPy |
| Visualization | Matplotlib, Seaborn, Plotly |
| Feature Engineering | StandardScaler, LabelEncoder, PCA |
| Models | Linear Regression, Logistic Regression, Naive Bayes, Decision Tree, Random Forest, SVM, MLP |
| Reporting | IEEE Paper (LaTeX & PDF), Markdown Documentation |

---

## üß≠ Learning Outcomes
- Mastered **supervised learning principles** including regression, classification, and evaluation.  
- Developed and deployed **machine learning models** for real-world datasets.  
- Strengthened understanding of **data preprocessing, scaling, and regularization**.  
- Built a **capstone project** applying ML in agriculture to improve productivity forecasting.  
- Created a complete research workflow ‚Äî from raw data to IEEE publication.

---

## üìÇ Repository Structure
